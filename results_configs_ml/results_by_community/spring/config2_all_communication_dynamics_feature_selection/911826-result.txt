--------------
Configuration:
Test: False
ONLY_COMMUNICATION_DYNAMICS_METRICS? True ['discussion_duration', 'discussion_size', 'contributors', 'core_developers', 'newbies', 'mean_time_between_comments', 'open_and_first']
ONLY_DISCUSSION_CONTENT_METRICS? False ['density_design_keywords', 'density_refactoring_keywords', 'number_design_keywords', 'number_refactoring_keywords', 'mean_number_of_words', 'number_of_words']
ONLY_ORGANIZATIONAL_DYNAMICS_METRICS? False ['newbies', 'newcomers_size', 'team_size', 'users_left_size', 'number_females', 'number_males']
Balance dataset? True random
Scale dataset? True
Feature reduction? True 5
CV for Hyper parameter search: grid 5 100
CV for evaluation: 10
Datasets: ['Spring-boot', 'Spring-security']
Models: ['svm', 'random-forest', 'decision-tree', 'logistic-regression', 'naive-bayes', 'gradient-boosting']
Deep Learning Models: ['neural-network']
Smell Granularity: ['implementation', 'design']
--------------
ML4SocialMetricsImpactfulPatches: Binary classification
Community: Spring
**** Smell granularity implementation
---- Retrieve labeled instances for dataset: ['Spring-boot', 'Spring-security']
raw number of impactful patches instances: 390
raw number of not impactful patches instances: 3825
impactful patches instance (after dropping NA)s: 286
not impactful patches instances (after dropping NA)s: 2970
instances before balancing: Counter({0: 2970, 1: 286})
instances after balancing: Counter({0: 286, 1: 286})
Features before reduction (total of 7): discussion_duration, discussion_size, contributors, core_developers, mean_time_between_comments, last_and_close, open_and_first
Features after reduction (total of 2): core_developers, last_and_close
Feature ranking: 3, 6, 2, 1, 5, 1, 4
Feature grid scores: mean_test_score, std_test_score, split0_test_score, split1_test_score, split2_test_score, split3_test_score, split4_test_score
Model LinearSVMModel
Execution: 1/12
Started at 2023-11-11 23:50:05
Test search started at 2023-11-11 23:50:05

Hyperparametrization:
{
  "C": 0.7039784741968872,
  "kernel": "linear",
  "shrinking": false
}
Best result: 0.6837528604118993
Cross validation started at 2023-11-11 23:50:06

Production model build started at 2023-11-11 23:50:06

Production Model Results:
Precision scores: 0.81, 0.64, 0.73, 0.76, 0.81, 0.62, 0.71, 0.75, 0.79, 0.85
Mean precision: 0.75

Recall scores: 0.72, 0.31, 0.57, 0.46, 0.61, 0.36, 0.52, 0.62, 0.66, 0.59
Mean recall: 0.54

Accuracy scores: 0.78, 0.57, 0.68, 0.67, 0.74, 0.58, 0.65, 0.70, 0.74, 0.74
Mean Accuracy:  0.68

F1 scores: 0.76, 0.42, 0.64, 0.58, 0.69, 0.45, 0.60, 0.68, 0.72, 0.69
Mean F1:  0.62

AUC scores: 0.78, 0.57, 0.68, 0.66, 0.73, 0.58, 0.65, 0.70, 0.74, 0.74
Mean AUC: 0.68
Features:core_developers, last_and_close
Coefficients:
[-4.01152386084345, 2.3982680560208585]
CSV,Spring,implementation,LinearSVMModel,0.75,0.54,0.68,0.62,236,50,131,155,0.68
Finished at 2023-11-11 23:50:06
TIME,Spring,implementation,LinearSVMModel,2023-11-11 23:50:05,2023-11-11 23:50:06
Model RandomForestModel
Execution: 2/12
Started at 2023-11-11 23:50:06
Test search started at 2023-11-11 23:50:06

Hyperparametrization:
{
  "bootstrap": false,
  "criterion": "entropy",
  "max_depth": 3,
  "max_features": "sqrt",
  "min_samples_split": 2,
  "n_estimators": 100
}
Best result: 0.6871090770404272
Cross validation started at 2023-11-11 23:52:51

Production model build started at 2023-11-11 23:52:51

Production Model Results:
Precision scores: 0.91, 0.64, 0.85, 0.71, 0.74, 0.94, 0.58, 0.77, 0.79, 0.88
Mean precision: 0.78

Recall scores: 0.34, 0.55, 0.61, 0.54, 0.61, 0.54, 0.48, 0.69, 0.38, 0.48
Mean recall: 0.52

Accuracy scores: 0.66, 0.62, 0.75, 0.67, 0.70, 0.75, 0.56, 0.74, 0.63, 0.70
Mean Accuracy:  0.68

F1 scores: 0.50, 0.59, 0.71, 0.61, 0.67, 0.68, 0.53, 0.73, 0.51, 0.62
Mean F1:  0.62

AUC scores: 0.66, 0.62, 0.75, 0.66, 0.70, 0.75, 0.56, 0.74, 0.64, 0.71
Mean AUC: 0.68
Feature Importances: 
core_developers                  : 0.7475
last_and_close                   : 0.2525

CSV,Spring,implementation,RandomForestModel,0.78,0.52,0.68,0.62,239,47,137,149,0.68
Finished at 2023-11-11 23:52:51
TIME,Spring,implementation,RandomForestModel,2023-11-11 23:50:06,2023-11-11 23:52:51
Model DecisionTreeModel
Execution: 3/12
Started at 2023-11-11 23:52:51
Test search started at 2023-11-11 23:52:51

Hyperparametrization:
{
  "criterion": "gini",
  "max_depth": 6,
  "max_features": "sqrt",
  "min_samples_split": 2,
  "splitter": "best"
}
Best result: 0.6853241800152555
Cross validation started at 2023-11-11 23:52:52

Production model build started at 2023-11-11 23:52:52

Production Model Results:
Precision scores: 0.69, 0.75, 0.70, 0.89, 0.69, 0.60, 0.81, 0.83, 0.75, 0.79
Mean precision: 0.75

Recall scores: 0.38, 0.52, 0.50, 0.61, 0.71, 0.54, 0.45, 0.34, 0.41, 0.66
Mean recall: 0.51

Accuracy scores: 0.60, 0.67, 0.65, 0.77, 0.70, 0.60, 0.67, 0.63, 0.63, 0.74
Mean Accuracy:  0.67

F1 scores: 0.49, 0.61, 0.58, 0.72, 0.70, 0.57, 0.58, 0.49, 0.53, 0.72
Mean F1:  0.60

AUC scores: 0.60, 0.67, 0.65, 0.77, 0.70, 0.60, 0.67, 0.64, 0.64, 0.74
Mean AUC: 0.67
Feature Importances: 
core_developers                  : 0.6512
last_and_close                   : 0.3488

CSV,Spring,implementation,DecisionTreeModel,0.75,0.51,0.67,0.60,235,51,140,146,0.67
Finished at 2023-11-11 23:52:52
TIME,Spring,implementation,DecisionTreeModel,2023-11-11 23:52:51,2023-11-11 23:52:52
Model LogisticRegressionModel
Execution: 4/12
Started at 2023-11-11 23:52:52
Test search started at 2023-11-11 23:52:52

Hyperparametrization:
{
  "C": 59.97234512558144,
  "max_iter": 50
}
Best result: 0.6766132723112128
Cross validation started at 2023-11-11 23:52:53

Production model build started at 2023-11-11 23:52:53

Production Model Results:
Precision scores: 0.81, 0.82, 0.80, 0.80, 0.78, 0.73, 0.78, 0.86, 0.80, 0.82
Mean precision: 0.80

Recall scores: 0.45, 0.48, 0.43, 0.43, 0.50, 0.39, 0.48, 0.62, 0.41, 0.48
Mean recall: 0.47

Accuracy scores: 0.67, 0.69, 0.67, 0.67, 0.68, 0.63, 0.67, 0.75, 0.65, 0.68
Mean Accuracy:  0.68

F1 scores: 0.58, 0.61, 0.56, 0.56, 0.61, 0.51, 0.60, 0.72, 0.55, 0.61
Mean F1:  0.59

AUC scores: 0.67, 0.69, 0.66, 0.66, 0.68, 0.63, 0.67, 0.76, 0.65, 0.69
Mean AUC: 0.68
Features:core_developers, last_and_close
Coefficients:
[-4.711951159461736, 7.021318476826965]
CSV,Spring,implementation,LogisticRegressionModel,0.80,0.47,0.68,0.59,253,33,152,134,0.68
Finished at 2023-11-11 23:52:53
TIME,Spring,implementation,LogisticRegressionModel,2023-11-11 23:52:52,2023-11-11 23:52:53
Model GaussianNaiveBayesModel
Execution: 5/12
Started at 2023-11-11 23:52:53
Test search started at 2023-11-11 23:52:53

Hyperparametrization:
{
  "var_smoothing": 1e-10
}
Best result: 0.510511060259344
Cross validation started at 2023-11-11 23:52:53

Production model build started at 2023-11-11 23:52:53

Production Model Results:
Precision scores: 0.50, 0.67, 1.00, 0.50, 0.50, 1.00, 0.00, 0.25, 1.00, 0.83
Mean precision: 0.62

Recall scores: 0.07, 0.07, 0.11, 0.04, 0.04, 0.04, 0.00, 0.03, 0.03, 0.17
Mean recall: 0.06

Accuracy scores: 0.50, 0.52, 0.56, 0.51, 0.51, 0.53, 0.49, 0.46, 0.51, 0.56
Mean Accuracy:  0.51

F1 scores: 0.12, 0.12, 0.19, 0.07, 0.07, 0.07, 0.00, 0.06, 0.07, 0.29
Mean F1:  0.11

AUC scores: 0.50, 0.52, 0.55, 0.50, 0.50, 0.52, 0.50, 0.46, 0.52, 0.57
Mean AUC: 0.51
(Not possible to collect feature importances)
CSV,Spring,implementation,GaussianNaiveBayesModel,0.62,0.06,0.51,0.11,277,9,269,17,0.51
Finished at 2023-11-11 23:52:53
TIME,Spring,implementation,GaussianNaiveBayesModel,2023-11-11 23:52:53,2023-11-11 23:52:53
Model GradientBoostingRegressorModel
Execution: 6/12
Started at 2023-11-11 23:52:53
Test search started at 2023-11-11 23:52:53

Hyperparametrization:
{
  "max_depth": 12,
  "min_samples_split": 4,
  "n_estimators": 10
}
Best result: 0.6818764302059497
Cross validation started at 2023-11-11 23:53:13

Production model build started at 2023-11-11 23:53:13

Production Model Results:
Precision scores: 0.70, 0.59, 0.78, 0.77, 0.80, 0.76, 0.89, 0.73, 0.88, 0.67
Mean precision: 0.76

Recall scores: 0.48, 0.34, 0.64, 0.61, 0.57, 0.57, 0.59, 0.66, 0.52, 0.41
Mean recall: 0.54

Accuracy scores: 0.64, 0.55, 0.74, 0.72, 0.72, 0.70, 0.75, 0.70, 0.72, 0.60
Mean Accuracy:  0.68

F1 scores: 0.57, 0.43, 0.71, 0.68, 0.67, 0.65, 0.71, 0.69, 0.65, 0.51
Mean F1:  0.63

AUC scores: 0.64, 0.55, 0.74, 0.72, 0.72, 0.70, 0.76, 0.70, 0.72, 0.60
Mean AUC: 0.68
Feature Importances: 
core_developers                  : 0.5038
last_and_close                   : 0.4962

CSV,Spring,implementation,GradientBoostingRegressorModel,0.76,0.54,0.68,0.63,237,49,132,154,0.68
Finished at 2023-11-11 23:53:13
TIME,Spring,implementation,GradientBoostingRegressorModel,2023-11-11 23:52:53,2023-11-11 23:53:13
**** Smell granularity design
---- Retrieve labeled instances for dataset: ['Spring-boot', 'Spring-security']
raw number of impactful patches instances: 334
raw number of not impactful patches instances: 3881
impactful patches instance (after dropping NA)s: 241
not impactful patches instances (after dropping NA)s: 3015
instances before balancing: Counter({0: 3015, 1: 241})
instances after balancing: Counter({0: 241, 1: 241})
Features before reduction (total of 7): discussion_duration, discussion_size, contributors, core_developers, mean_time_between_comments, last_and_close, open_and_first
Features after reduction (total of 2): contributors, last_and_close
Feature ranking: 3, 6, 1, 2, 4, 1, 5
Feature grid scores: mean_test_score, std_test_score, split0_test_score, split1_test_score, split2_test_score, split3_test_score, split4_test_score
Model LinearSVMModel
Execution: 7/12
Started at 2023-11-11 23:53:13
Test search started at 2023-11-11 23:53:13

Hyperparametrization:
{
  "C": 0.6538329456332215,
  "kernel": "linear",
  "shrinking": false
}
Best result: 0.6720575601374571
Cross validation started at 2023-11-11 23:53:13

Production model build started at 2023-11-11 23:53:13

Production Model Results:
Precision scores: 0.86, 0.67, 0.65, 0.77, 0.83, 0.69, 0.83, 0.83, 0.75, 1.00
Mean precision: 0.79

Recall scores: 0.50, 0.56, 0.54, 0.42, 0.42, 0.38, 0.42, 0.42, 0.38, 0.46
Mean recall: 0.45

Accuracy scores: 0.71, 0.63, 0.62, 0.65, 0.67, 0.60, 0.67, 0.67, 0.62, 0.73
Mean Accuracy:  0.66

F1 scores: 0.63, 0.61, 0.59, 0.54, 0.56, 0.49, 0.56, 0.56, 0.50, 0.63
Mean F1:  0.57

AUC scores: 0.71, 0.63, 0.62, 0.65, 0.67, 0.60, 0.67, 0.67, 0.62, 0.73
Mean AUC: 0.66
Features:contributors, last_and_close
Coefficients:
[5.3242537390820335, 1.6481683025795182]
CSV,Spring,design,LinearSVMModel,0.79,0.45,0.66,0.57,209,32,133,108,0.66
Finished at 2023-11-11 23:53:13
TIME,Spring,design,LinearSVMModel,2023-11-11 23:53:13,2023-11-11 23:53:13
Model RandomForestModel
Execution: 8/12
Started at 2023-11-11 23:53:13
Test search started at 2023-11-11 23:53:13

Hyperparametrization:
{
  "bootstrap": true,
  "criterion": "gini",
  "max_depth": 6,
  "max_features": null,
  "min_samples_split": 5,
  "n_estimators": 10
}
Best result: 0.6908505154639175
Cross validation started at 2023-11-11 23:56:03

Production model build started at 2023-11-11 23:56:03

Production Model Results:
Precision scores: 0.68, 0.83, 0.69, 0.62, 0.81, 0.79, 0.70, 0.71, 0.83, 0.71
Mean precision: 0.74

Recall scores: 0.62, 0.60, 0.46, 0.42, 0.54, 0.46, 0.58, 0.62, 0.42, 0.71
Mean recall: 0.54

Accuracy scores: 0.67, 0.73, 0.62, 0.58, 0.71, 0.67, 0.67, 0.69, 0.67, 0.71
Mean Accuracy:  0.67

F1 scores: 0.65, 0.70, 0.55, 0.50, 0.65, 0.58, 0.64, 0.67, 0.56, 0.71
Mean F1:  0.62

AUC scores: 0.67, 0.74, 0.62, 0.58, 0.71, 0.67, 0.67, 0.69, 0.67, 0.71
Mean AUC: 0.67
Feature Importances: 
contributors                     : 0.5250
last_and_close                   : 0.4750

CSV,Spring,design,RandomForestModel,0.74,0.54,0.67,0.62,193,48,110,131,0.67
Finished at 2023-11-11 23:56:03
TIME,Spring,design,RandomForestModel,2023-11-11 23:53:13,2023-11-11 23:56:03
Model DecisionTreeModel
Execution: 9/12
Started at 2023-11-11 23:56:03
Test search started at 2023-11-11 23:56:03

Hyperparametrization:
{
  "criterion": "gini",
  "max_depth": 6,
  "max_features": null,
  "min_samples_split": 2,
  "splitter": "best"
}
Best result: 0.6887242268041236
Cross validation started at 2023-11-11 23:56:04

Production model build started at 2023-11-11 23:56:04

Production Model Results:
Precision scores: 0.73, 0.63, 1.00, 0.81, 0.58, 0.72, 0.83, 0.60, 0.74, 0.73
Mean precision: 0.74

Recall scores: 0.46, 0.48, 0.58, 0.54, 0.46, 0.54, 0.83, 0.50, 0.58, 0.46
Mean recall: 0.54

Accuracy scores: 0.65, 0.59, 0.79, 0.71, 0.56, 0.67, 0.83, 0.58, 0.69, 0.65
Mean Accuracy:  0.67

F1 scores: 0.56, 0.55, 0.74, 0.65, 0.51, 0.62, 0.83, 0.55, 0.65, 0.56
Mean F1:  0.62

AUC scores: 0.65, 0.59, 0.79, 0.71, 0.56, 0.67, 0.83, 0.58, 0.69, 0.65
Mean AUC: 0.67
Feature Importances: 
contributors                     : 0.5785
last_and_close                   : 0.4215

CSV,Spring,design,DecisionTreeModel,0.74,0.54,0.67,0.62,193,48,110,131,0.67
Finished at 2023-11-11 23:56:04
TIME,Spring,design,DecisionTreeModel,2023-11-11 23:56:03,2023-11-11 23:56:04
Model LogisticRegressionModel
Execution: 10/12
Started at 2023-11-11 23:56:04
Test search started at 2023-11-11 23:56:04

Hyperparametrization:
{
  "C": 71.8953290411915,
  "max_iter": 50
}
Best result: 0.6742053264604811
Cross validation started at 2023-11-11 23:56:05

Production model build started at 2023-11-11 23:56:05

Production Model Results:
Precision scores: 0.79, 0.88, 0.73, 0.77, 0.81, 0.79, 0.83, 0.75, 0.77, 0.83
Mean precision: 0.80

Recall scores: 0.46, 0.60, 0.46, 0.42, 0.54, 0.46, 0.42, 0.50, 0.42, 0.42
Mean recall: 0.47

Accuracy scores: 0.67, 0.76, 0.65, 0.65, 0.71, 0.67, 0.67, 0.67, 0.65, 0.67
Mean Accuracy:  0.67

F1 scores: 0.58, 0.71, 0.56, 0.54, 0.65, 0.58, 0.56, 0.60, 0.54, 0.56
Mean F1:  0.59

AUC scores: 0.67, 0.76, 0.65, 0.65, 0.71, 0.67, 0.67, 0.67, 0.65, 0.67
Mean AUC: 0.67
Features:contributors, last_and_close
Coefficients:
[4.986995069252359, 6.806174404425866]
CSV,Spring,design,LogisticRegressionModel,0.80,0.47,0.67,0.59,212,29,128,113,0.67
Finished at 2023-11-11 23:56:05
TIME,Spring,design,LogisticRegressionModel,2023-11-11 23:56:04,2023-11-11 23:56:05
Model GaussianNaiveBayesModel
Execution: 11/12
Started at 2023-11-11 23:56:05
Test search started at 2023-11-11 23:56:05

Hyperparametrization:
{
  "var_smoothing": 1e-10
}
Best result: 0.5269759450171823
Cross validation started at 2023-11-11 23:56:05

Production model build started at 2023-11-11 23:56:05

Production Model Results:
Precision scores: 0.50, 1.00, 0.50, 1.00, 1.00, 0.25, 0.50, 1.00, 0.80, 1.00
Mean precision: 0.76

Recall scores: 0.08, 0.12, 0.08, 0.08, 0.04, 0.04, 0.04, 0.12, 0.17, 0.12
Mean recall: 0.09

Accuracy scores: 0.51, 0.55, 0.50, 0.54, 0.52, 0.46, 0.50, 0.56, 0.56, 0.56
Mean Accuracy:  0.53

F1 scores: 0.14, 0.21, 0.14, 0.15, 0.08, 0.07, 0.08, 0.22, 0.28, 0.22
Mean F1:  0.16

AUC scores: 0.50, 0.56, 0.50, 0.54, 0.52, 0.46, 0.50, 0.56, 0.56, 0.56
Mean AUC: 0.53
(Not possible to collect feature importances)
CSV,Spring,design,GaussianNaiveBayesModel,0.76,0.09,0.53,0.16,232,9,219,22,0.53
Finished at 2023-11-11 23:56:05
TIME,Spring,design,GaussianNaiveBayesModel,2023-11-11 23:56:05,2023-11-11 23:56:05
Model GradientBoostingRegressorModel
Execution: 12/12
Started at 2023-11-11 23:56:05
Test search started at 2023-11-11 23:56:05

Hyperparametrization:
{
  "max_depth": 3,
  "min_samples_split": 3,
  "n_estimators": 50
}
Best result: 0.6805197594501718
Cross validation started at 2023-11-11 23:56:21

Production model build started at 2023-11-11 23:56:21

Production Model Results:
Precision scores: 0.58, 0.67, 0.80, 0.83, 0.93, 0.79, 0.78, 0.64, 0.68, 0.76
Mean precision: 0.75

Recall scores: 0.46, 0.48, 0.83, 0.62, 0.54, 0.62, 0.58, 0.58, 0.54, 0.54
Mean recall: 0.58

Accuracy scores: 0.57, 0.61, 0.81, 0.75, 0.75, 0.73, 0.71, 0.62, 0.65, 0.69
Mean Accuracy:  0.69

F1 scores: 0.51, 0.56, 0.82, 0.71, 0.68, 0.70, 0.67, 0.61, 0.60, 0.63
Mean F1:  0.65

AUC scores: 0.57, 0.61, 0.81, 0.75, 0.75, 0.73, 0.71, 0.63, 0.65, 0.69
Mean AUC: 0.69
Feature Importances: 
contributors                     : 0.5217
last_and_close                   : 0.4783

CSV,Spring,design,GradientBoostingRegressorModel,0.75,0.58,0.69,0.65,192,49,101,140,0.69
Finished at 2023-11-11 23:56:21
TIME,Spring,design,GradientBoostingRegressorModel,2023-11-11 23:56:05,2023-11-11 23:56:21
